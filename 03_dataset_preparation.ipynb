{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a TensorFlow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow tensorflow-datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bair_robot_pushing_small',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'coco2014',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'dummy_dataset_shared_generator',\n",
       " 'dummy_mnist',\n",
       " 'fashion_mnist',\n",
       " 'image_label_folder',\n",
       " 'imagenet2012',\n",
       " 'imdb_reviews',\n",
       " 'lm1b',\n",
       " 'lsun',\n",
       " 'mnist',\n",
       " 'moving_mnist',\n",
       " 'nsynth',\n",
       " 'omniglot',\n",
       " 'open_images_v4',\n",
       " 'quickdraw_bitmap',\n",
       " 'squad',\n",
       " 'starcraft_video',\n",
       " 'svhn_cropped',\n",
       " 'tf_flowers',\n",
       " 'wmt_translate_ende',\n",
       " 'wmt_translate_enfr']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetsImageNet():\n",
    "    imageNetBuilder = tfds.builder(\"imagenet2012\")\n",
    "    imageNetBuilder.download_and_prepare()\n",
    "    return ({\n",
    "        'train': imageNetBuilder.as_dataset(split=tfds.Split.TRAIN), \n",
    "        'valid': imageNetBuilder.as_dataset(split=tfds.Split.VALIDATION),\n",
    "        'test': imageNetBuilder.as_dataset(split=tfds.Split.TEST)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageNet = getDatasetsImageNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectRawImgList(inputDir, outputDir):\n",
    "    result = {'pathnames': list(), 'labelStrings': list(), 'newPathnames': list()}\n",
    "    cnt = 0\n",
    "    with os.scandir(inputDir) as inp:\n",
    "        for entry in inp:\n",
    "            if not os.path.isdir(entry):\n",
    "                continue\n",
    "            print(\"Processing directory {}\".format(os.path.abspath(entry)))\n",
    "            category = os.path.basename(entry)\n",
    "            print(\"Category name: {}\".format(category))\n",
    "            for fileEntry in os.scandir(entry):\n",
    "                #print(\"File {}\".format(os.path.basename(fileEntry)))\n",
    "                #result.append((os.path.abspath(fileEntry), category))\n",
    "                result['pathnames'].append(os.path.abspath(fileEntry))\n",
    "                result['labelStrings'].append(category)\n",
    "                result['newPathnames'].append(os.path.join(outputDir, \"{:05}.png\".format(cnt)))\n",
    "                cnt += 1\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formFileNameDataSet(inputDir, outputDir):\n",
    "    rawCollection = collectRawImgList(inputDir, outputDir)\n",
    "    \n",
    "    placePathnames = tf.placeholder(shape=(None,), dtype=tf.dtypes.string)\n",
    "    placeLabelStrings = tf.placeholder(shape=(None,), dtype=tf.dtypes.string)\n",
    "    placeNewPathnames = tf.placeholder(shape=(None,), dtype=tf.dtypes.string)\n",
    "    \n",
    "    dataSetPathnames = tf.data.Dataset.from_tensor_slices(placePathnames)\n",
    "    dataSetLabelStrings = tf.data.Dataset.from_tensor_slices(placeLabelStrings)\n",
    "    dataSetNewPathnames = tf.data.Dataset.from_tensor_slices(placeNewPathnames)\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((dataSetPathnames, dataSetLabelStrings, dataSetNewPathnames))\n",
    "    \n",
    "    return (dataset, rawCollection, (placePathnames, placeLabelStrings, placeNewPathnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformFiles(inputDir, outputDir, targetHeight=127, targetWidth=127):\n",
    "    \n",
    "    if os.path.exists(outputDir):\n",
    "        shutil.rmtree(outputDir)\n",
    "        \n",
    "    os.mkdir(outputDir)\n",
    "    outputDirOld = outputDir\n",
    "    outputDir = os.path.join(outputDir, 'img')\n",
    "    os.mkdir(outputDir)\n",
    "    \n",
    "    fnameDataset, rawCollection, placeholders = formFileNameDataSet(inputDir, outputDir)\n",
    "    \n",
    "    with open(os.path.join(outputDirOld, \"fileLabels.txt\"), \"w\") as labFile:\n",
    "        for fn, lab in zip(rawCollection['newPathnames'], rawCollection['labelStrings']):\n",
    "            labFile.write(\"'{}' {}\\n\".format(os.path.basename(fn), lab))\n",
    "        \n",
    "    \n",
    "    def _howToTransform(pathname, labelString, newPathname):\n",
    "        img = tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(pathname)), \n",
    "                                     [targetHeight, targetWidth])\n",
    "        #writeOp = tf.write_file(newPathname, tf.image.encode_png(tf.cast(img, tf.uint8)))\n",
    "        return (pathname, labelString, newPathname, img)\n",
    "    \n",
    "    fnameDataset = fnameDataset.map(_howToTransform)\n",
    "    iterator = fnameDataset.make_initializable_iterator()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(iterator.initializer, \n",
    "                 feed_dict={placeholders[0]: rawCollection['pathnames'],\n",
    "                           placeholders[1]: rawCollection['labelStrings'],\n",
    "                           placeholders[2]: rawCollection['newPathnames']})\n",
    "        nextElement = iterator.get_next()\n",
    "        writeOp = tf.write_file(nextElement[2], tf.image.encode_png(tf.cast(nextElement[3], tf.uint8)))\n",
    "        while True:\n",
    "            try:\n",
    "                val, wop = sess.run([nextElement, writeOp])\n",
    "                #print(val)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory /home/ivan/datasets/bilbao2019/raw/bench\n",
      "Category name: bench\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/textad\n",
      "Category name: textad\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/washbasin\n",
      "Category name: washbasin\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/manhole\n",
      "Category name: manhole\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/staircase\n",
      "Category name: staircase\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/urn\n",
      "Category name: urn\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/socket\n",
      "Category name: socket\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/ad\n",
      "Category name: ad\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/urinal\n",
      "Category name: urinal\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/gate\n",
      "Category name: gate\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/container\n",
      "Category name: container\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/switch\n",
      "Category name: switch\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/toilet\n",
      "Category name: toilet\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/logo\n",
      "Category name: logo\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/door\n",
      "Category name: door\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/tap\n",
      "Category name: tap\n",
      "Processing directory /home/ivan/datasets/bilbao2019/raw/extension\n",
      "Category name: extension\n",
      "WARNING:tensorflow:From /home/ivan/tools/python_venv/python37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "transformFiles(\"/home/ivan/datasets/bilbao2019/raw\",\n",
    "               \"/home/ivan/datasets/bilbao2019/processed\", \n",
    "               targetHeight=227, targetWidth=227)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have prepared the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
